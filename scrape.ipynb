{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "216\n",
      "     index icon               title   \n",
      "215    215   CP  Commercial / PLACE  \\\n",
      "\n",
      "                                                   url   \n",
      "215  https://hksinc.sharepoint.com/sites/Commercial...  \\\n",
      "\n",
      "                                           description  \n",
      "215  This Group is for Shanghai Commercial/PLACE me...  \n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "\n",
    "#convert the sites into a df\n",
    "sitesdf = pandas.DataFrame(columns=('icon', 'title', 'url', 'description'))\n",
    "f = open(\"hkssites.txt\", \"r\")\n",
    "row = 0\n",
    "icon =\"\"\n",
    "title=\"\"\n",
    "url=\"\"\n",
    "desc=\"\"\n",
    "for x in f:\n",
    "    x =x.strip()\n",
    "    if x == \"\":\n",
    "        continue\n",
    "    if len(x) == 1 or len(x) == 2:\n",
    "        #add previous site and reset\n",
    "        if  title+url != \"\":\n",
    "            sitesdf.loc[row] = [icon,title,url,desc]\n",
    "            row+=1\n",
    "            title=\"\"\n",
    "            url=\"\"\n",
    "        icon=x    \n",
    "    if \"http\" in x:\n",
    "        url = x\n",
    "    if url == \"\":\n",
    "        title =x\n",
    "    else :\n",
    "        desc = x\n",
    "    \n",
    "f.close()\n",
    "sitesdf = sitesdf.reset_index()  # make sure indexes pair with number of rows\n",
    "print(sitesdf.shape[0])\n",
    "print(sitesdf.tail(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Purp1eGusGus\n"
     ]
    }
   ],
   "source": [
    "#set up credentials + imports\n",
    "from office365.runtime.auth.user_credential import UserCredential\n",
    "from office365.sharepoint.client_context import ClientContext\n",
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "#set up credentials\n",
    "load_dotenv(\".env\", override=True)\n",
    "userCredential = UserCredential(os.getenv('user'),os.getenv('password') )\n",
    "print(os.getenv('password'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sitepages(ctx):\n",
    "    #list pages relative to site_url\n",
    "    site_pages = ctx.site_pages.pages.get().execute_query()\n",
    "    # for site_page in site_pages:  # type: SitePage\n",
    "    #     print(site_page.file_name)\n",
    "    print(len(site_pages))\n",
    "    return site_pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns the content from url\n",
    "def content(ctx, relative_url):\n",
    "    file = ctx.web.get_file_by_server_relative_url(relative_url)\n",
    "    file_item = file.listItemAllFields.select([\"CanvasContent1\", \"LayoutWebpartsContent\"]).get().execute_query()\n",
    "    \n",
    "    #print(content)\n",
    "    return file_item.properties.get(\"CanvasContent1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://hksinc.sharepoint.com\n",
      "79\n",
      "no content\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# iterates all the sites from the txt file gets site pages and then content from each and stores to a text file\n",
    "# Create a directory to store the text files\n",
    "if not os.path.exists(\"text/\"):\n",
    "        os.mkdir(\"text/\")\n",
    "\n",
    "if not os.path.exists(\"text/hksinc.sharepoint.com/\"):\n",
    "        os.mkdir(\"text/hksinc.sharepoint.com/\")\n",
    "\n",
    "# Create a directory to store the csv files\n",
    "if not os.path.exists(\"processed\"):\n",
    "        os.mkdir(\"processed\")\n",
    "        \n",
    "#iterate sites        \n",
    "for index, row in sitesdf.head(1).iterrows():\n",
    "    site_url = row[\"url\"]\n",
    "    ctx = ClientContext(site_url).with_credentials(userCredential)\n",
    "    web = ctx.web\n",
    "    ctx.load(web)\n",
    "    ctx.execute_query()\n",
    "    print(site_url)\n",
    "    #print(site_url.replace(\"https://hksinc.sharepoint.com\",\"\"))\n",
    "    for page in sitepages(ctx):\n",
    "        relative_url = site_url.replace(\"https://hksinc.sharepoint.com\",\"\")+ \"/SitePages/\"+page.file_name\n",
    "        \n",
    "        #get content for site page\n",
    "        cleanUrl = relative_url.replace(\"/\", \"_\").replace(\"?\", \"_\").replace(\":\", \"_\").replace(\".\", \"_\")\n",
    "        #print(cleanUrl)\n",
    "        try:\n",
    "            t = content(ctx, relative_url)\n",
    "        except:\n",
    "            print(\"no content\")\n",
    "        else:\n",
    "            if t is not None:\n",
    "                soup = BeautifulSoup(t)\n",
    "                    # Get the text but remove the tags\n",
    "                text = soup.get_text()\n",
    "                if text !=\"\":\n",
    "                    with open('text/hksinc.sharepoint.com/'+cleanUrl + \".txt\", \"w\", encoding=\"utf-8\") as f:    \n",
    "                        \n",
    "\n",
    "                        # If the crawler gets to a page that requires JavaScript, it will stop the crawl\n",
    "                        if (\"You need to enable JavaScript to run this app.\" in text):\n",
    "                            print(\"Unable to parse page \" + url + \" due to JavaScript being required\")\n",
    "                        \n",
    "                        # Otherwise, write the text to the file in the text directory\n",
    "                        f.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Web title: Source\n",
      "{'Description': 'https://hksinc.sharepoint.com/_layouts/15/getpreview.ashx?guidSite=1d26113b-6e40-4404-814d-038f1605cea0&guidWeb=501cc4e4-f8f8-43a7-9b83-45e8756fa5db&guidFile=1cb893cc-4766-41bc-80a4-22aea687cd9f', 'Url': 'https://hksinc.sharepoint.com/_layouts/15/getpreview.ashx?guidSite=1d26113b-6e40-4404-814d-038f1605cea0&guidWeb=501cc4e4-f8f8-43a7-9b83-45e8756fa5db&guidFile=1cb893cc-4766-41bc-80a4-22aea687cd9f'}\n"
     ]
    }
   ],
   "source": [
    "#checking the process on the base url and relative url\n",
    "from office365.runtime.auth.user_credential import UserCredential\n",
    "from office365.sharepoint.client_context import ClientContext\n",
    "site_url = \"https://hksinc.sharepoint.com\"\n",
    "ctx = ClientContext(site_url).with_credentials(userCredential)\n",
    "web = ctx.web\n",
    "ctx.load(web)\n",
    "ctx.execute_query()\n",
    "print(\"Web title: {0}\".format(web.properties['Title'])) \n",
    "\n",
    "file = ctx.web.get_file_by_server_relative_url(\"/SitePages/Breaking-News--Fast-Company-Announces-Project-Connect.aspx\")\n",
    "\n",
    "file_item = file.listItemAllFields.select([\"CanvasContent1\", \"LayoutWebpartsContent\",\"BannerImageUrl\"]).get().execute_query()\n",
    "print(file_item.properties.get(\"BannerImageUrl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "Home.aspx\n",
      "Overview.aspx\n",
      "Process.aspx\n",
      "Synthesis-and-Documentation.aspx\n",
      "Data.aspx\n",
      "Fulcrum.aspx\n",
      "Annotated-Plan.aspx\n",
      "Photo-Essay.aspx\n",
      "Shadowing.aspx\n",
      "Behavior-Mapping.aspx\n",
      "Interviewing.aspx\n"
     ]
    }
   ],
   "source": [
    "#list pages relative to site_url\n",
    "site_pages = ctx.site_pages.pages.get().execute_query()\n",
    "\n",
    "print(len(site_pages))\n",
    "for site_page in site_pages:  # type: SitePage\n",
    "    print(site_page.file_name)\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
